---
permalink: /
title: "Yuanzhi Zhu - Homepage"
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a VLM and LLM researcher, a senior algorithm engineer at Alibaba Tongyi Lab (formerly Alibaba Damo Academy), and a core team member of Qwen2.5-VL, Qwen2.5-Omni, Qwen3, etc. I received my bachelor's and master's degrees from South China University of Technology, and I am engaged in CV and OCR research. After graduation, I joined Alibaba to conduct research in OCR, T2I, VLM, LLM, etc., which promoted the development of OCR expert models and the era of large models, and achieved technological breakthroughs many times. I have both model implementation experience and algorithm development experience. After absorbing it, I published more than ten papers (four papers as the first author) in top journals such as CVPR, ECCV, and AAAI, and the number of Google Scholar citations was 3000+.



# üìù Selected Publications


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv 2025</div><img src='images/Qwen2.5-VL-framework.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Qwen2.5-VL Technical Report](https://arxiv.org/abs/2502.13923)

Shuai Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Sibo Song, Kai Dang, Peng Wang, Shijie Wang, Jun Tang, Humen Zhong, <span style="color:PaleVioletRed;">Yuanzhi Zhu</span>, Mingkun Yang, Zhaohai Li, Jianqiang Wan, Pengfei Wang, Wei Ding, Zheren Fu, Yiheng Xu, Jiabo Ye, Xi Zhang, Tianbao Xie, Zesen Cheng, Hang Zhang, Zhibo Yang, Haiyang Xu, Junyang Lin.

[PDF](https://arxiv.org/abs/2502.13923) [Code]() <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- TD.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV 2024</div><img src='images/SceneVTG-poster.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Visual Text Generation in the Wild](https://arxiv.org/abs/2501.02962)

<span style="color:PaleVioletRed;">Yuanzhi Zhu</span>, Jiawei Liu, Feiyu Gao, Wenyu Liu, Xinggang Wang, Peng Wang, Fei Huang, Cong Yao, Zhibo Yang.

[PDF](https://arxiv.org/abs/2501.02962) [Code]() [Slides]() <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- TD.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2023</div><img src='images/CTIG-poster.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Conditional Text Image Generation with Diffusion Models](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_Conditional_Text_Image_Generation_With_Diffusion_Models_CVPR_2023_paper.pdf)

<span style="color:PaleVioletRed;">Yuanzhi Zhu</span>, Zhaohai Li, Tianwei Wang, Mengchao He, Cong Yao.

[PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_Conditional_Text_Image_Generation_With_Diffusion_Models_CVPR_2023_paper.pdf) [Code]() [Slides]() <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- TD.
</div>
</div>


# More Papers

[//] (- Qwen2. 5-vl technical report. 2025. [[pdf]](https://arxiv.org/abs/2502.13923) Shuai Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Sibo Song, Kai Dang, Peng Wang, Shijie Wang, Jun Tang, Humen Zhong, <span style="color:PaleVioletRed;">Yuanzhi Zhu</span>, Mingkun Yang, Zhaohai Li, Jianqiang Wan, Pengfei Wang, Wei Ding, Zheren Fu, Yiheng Xu, Jiabo Ye, Xi Zhang, Tianbao Xie, Zesen Cheng, Hang Zhang, Zhibo Yang, Haiyang Xu, Junyang Lin.)
[//] (- Visual text generation in the wild. ECCV 2024. [[pdf]](https://arxiv.org/abs/2501.02962) <span style="color:PaleVioletRed;">Yuanzhi Zhu</span>, Jiawei Liu, Feiyu Gao, Wenyu Liu, Xinggang Wang, Peng Wang, Fei Huang, Cong Yao, Zhibo Yang.)
[//] (- Conditional text image generation with diffusion models. CVPR 2023 [[pdf]](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_Conditional_Text_Image_Generation_With_Diffusion_Models_CVPR_2023_paper.pdf) <span style="color:PaleVioletRed;">Yuanzhi Zhu</span>, Zhaohai Li, Tianwei Wang, Mengchao He, Cong Yao.)
- Qwen3 Technical Report. **arXiv 2025**. [[pdf]](https://arxiv.org/abs/2505.09388) An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui et al. [Contributors]
- Qwen2.5-Omni Technical Report. **arXiv 2025**. [[pdf]](https://arxiv.org/abs/2503.20215) Jin Xu, Zhifang Guo, Jinzheng He, Hangrui Hu, Ting He, Shuai Bai et al. [Contributors]
- Implicit Feature Alignment: Learn to Convert Text Recognizer to Text Spotter. **CVPR 2021**. [[pdf]](https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Implicit_Feature_Alignment_Learn_To_Convert_Text_Recognizer_to_Text_CVPR_2021_paper.pdf) Tianwei Wang, <span style="color:PaleVioletRed;">Yuanzhi Zhu</span>, Lianwen Jin, Dezhi Peng, Zhe Li, Mengchao He, Yongpan Wang, Canjie Luo.
- Hiercode: A Lightweight Hierarchical Codebook for Zero-Shot Chinese Text Recognition. **PR 2025**. [[pdf]](https://www.sciencedirect.com/science/article/abs/pii/S0031320324007143) Yuyi Zhang, <span style="color:PaleVioletRed;">Yuanzhi Zhu</span>, Dezhi Peng, Peirong Zhang, Zhenhua Yang, Zhibo Yang, Cong Yao, Lianwen Jin.
- SceneVTG++: Controllable Multilingual Visual Text Generation in the Wild. **arXiv 2025**. [[pdf]](https://arxiv.org/pdf/2501.02962) Jiawei Liu, <span style="color:PaleVioletRed;">Yuanzhi Zhu</span>, Feiyu Gao, Zhibo Yang, Peng Wang, Junyang Lin, Xinggang Wang, Wenyu Liu.
- SLOGAN: Handwriting Style Synthesis for Arbitrary-Length and Out-of-Vocabulary Text. **IEEE TNNLS 2022**. [[pdf]](https://ieeexplore.ieee.org/abstract/document/9722567/) Canjie Luo, <span style="color:PaleVioletRed;">Yuanzhi Zhu</span>, Lianwen Jin, Zhe Li, Dezhi Peng. 
- Learn to Augment: Joint Data Augmentation and Network Optimization for Text Recognition. **CVPR 2020**. [[pdf]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Luo_Learn_to_Augment_Joint_Data_Augmentation_and_Network_Optimization_for_CVPR_2020_paper.pdf) Canjie Luo, <span style="color:PaleVioletRed;">Yuanzhi Zhu</span>, Lianwen Jin, Yongpan Wang.
- Decoupled Attention Network for Text Recognition. **AAAI 2020**. [[pdf]](https://ojs.aaai.org/index.php/AAAI/article/view/6903) Tianwei Wang, <span style="color:PaleVioletRed;">Yuanzhi Zhu</span>, Lianwen Jin, Canjie Luo, Xiaoxue Chen, Yaqiang Wu, Qianying Wang, Mingxiang Cai.
- Text Recognition in the Wild: A Survey. **ACM CSUR 2021**. [[pdf]](https://dl.acm.org/doi/abs/10.1145/3440756) Xiaoxue Chen, Lianwen Jin, <span style="color:PaleVioletRed;">Yuanzhi Zhu</span>, Canjie Luo, Tianwei Wang.
- Aggregation Cross-Entropy for Sequence Recognition. **CVPR 2019**. [[pdf]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Xie_Aggregation_Cross-Entropy_for_Sequence_Recognition_CVPR_2019_paper.pdf) Zecheng Xie, Yaoxiong Huang, <span style="color:PaleVioletRed;">Yuanzhi Zhu</span>, Lianwen Jin, Yuliang Liu, Lele Xie.


# üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìñ Educations
- *2018.09 - 2021.06 (now)*, Master of Engineering, South China University of Technology.
  Computer Vision, Optical Character Recognition
  - Winner of four domestic and international competitions in the field.
  - Published 6 papers in top-tier conferences and journals.
  - National Scholarship.
    
- *2014.09 - 2018.06*, Bachelor of Engineering, South China University of Technology.
  Information Engineering (Elite Program)
  - Received National Endeavor Scholarship for two years.
  - Recommended for postgraduate admission without an entrance exam.


# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
