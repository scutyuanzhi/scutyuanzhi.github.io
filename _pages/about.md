---
permalink: /
title: "Yuanzhi Zhu - Homepage"
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a VLM and LLM researcher, a senior algorithm engineer at Alibaba Tongyi Lab (formerly Alibaba Damo Academy), and a core team member of Qwen2.5-VL, Qwen2.5-Omni, Qwen3, etc. I received my bachelor's and master's degrees from South China University of Technology, and I am engaged in CV and OCR research. After graduation, I joined Alibaba to conduct research in OCR, T2I, VLM, LLM, etc., which promoted the development of OCR expert models and the era of large models, and achieved technological breakthroughs many times. I have both model implementation experience and algorithm development experience. After absorbing it, I published more than ten papers (four papers as the first author) in top journals such as CVPR, ECCV, and AAAI, and the number of Google Scholar citations was 3000+.



# üìù Selected Publications


# More Papers
- Qwen2. 5-vl technical report. 2025. [[pdf]](https://arxiv.org/abs/2502.13923) Shuai Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Sibo Song, Kai Dang, Peng Wang, Shijie Wang, Jun Tang, Humen Zhong, **Yuanzhi Zhu**, Mingkun Yang, Zhaohai Li, Jianqiang Wan, Pengfei Wang, Wei Ding, Zheren Fu, Yiheng Xu, Jiabo Ye, Xi Zhang, Tianbao Xie, Zesen Cheng, Hang Zhang, Zhibo Yang, Haiyang Xu, Junyang Lin.
- Qwen3 technical report. 2025. [[pdf]](https://arxiv.org/abs/2505.09388) An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui et al. [Contributors]
- Qwen2. 5-omni technical report. 2025. [pdf](https://arxiv.org/abs/2503.20215) Jin Xu, Zhifang Guo, Jinzheng He, Hangrui Hu, Ting He, Shuai Bai et al. [Contributors]
- Visual text generation in the wild. ECCV 2024. [[pdf]] **Yuanzhi Zhu**, Jiawei Liu, Feiyu Gao, Wenyu Liu, Xinggang Wang, Peng Wang, Fei Huang, Cong Yao, Zhibo Yang
- Conditional text image generation with diffusion models. <span style="color:PaleVioletRed;">CVPR 2023</span>. [[pdf]] **Yuanzhi Zhu**, Zhaohai Li, Tianwei Wang, Mengchao He, Cong Yao
- Hiercode: A lightweight hierarchical codebook for zero-shot chinese text recognition. Pattern Recognition 2025. [pdf] Yuyi Zhang, **Yuanzhi Zhu**, Dezhi Peng, Peirong Zhang, Zhenhua Yang, Zhibo Yang, Cong Yao, Lianwen Jin
- Implicit feature alignment: learn to convert text recognizer to text spotter. CVPR 2021. [pdf] Tianwei Wang, **Yuanzhi Zhu**, Lianwen Jin, Dezhi Peng, Zhe Li, Mengchao He, Yongpan Wang, Canjie Luo
- SLOGAN: handwriting style synthesis for arbitrary-length and out-of-vocabulary text. IEEE transactions on neural networks and learning systems 2022. [pdf] Canjie Luo, **Yuanzhi Zhu**, Lianwen Jin, Zhe Li, Dezhi Peng
- Learn to augment: Joint data augmentation and network optimization for text recognition. CVPR 2020. [pdf] Canjie Luo, **Yuanzhi Zhu**, Lianwen Jin, Yongpan Wang
- Decoupled attention network for text recognition. AAAI 2020. [pdf] Tianwei Wang, **Yuanzhi Zhu**, Lianwen Jin, Canjie Luo, Xiaoxue Chen, Yaqiang Wu, Qianying Wang, Mingxiang Cai.
- Text recognition in the wild: A survey. ACM Computing Surveys (CSUR) 2021. [pdf] Xiaoxue Chen, Lianwen Jin, **Yuanzhi Zhu**, Canjie Luo, Tianwei Wang
- Aggregation cross-entropy for sequence recognition. CVPR 2019. [pdf] Zecheng Xie, Yaoxiong Huang, **Yuanzhi Zhu**, Lianwen Jin, Yuliang Liu, Lele Xie
- SceneVTG++: Controllable Multilingual Visual Text Generation in the Wild. 2025. [pdf] Jiawei Liu, **Yuanzhi Zhu**, Feiyu Gao, Zhibo Yang, Peng Wang, Junyang Lin, Xinggang Wang, Wenyu Liu

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**

# üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìñ Educations
- *2018.09 - 2021.06 (now)*, Master of Engineering, South China University of Technology.
  Computer Vision, Optical Character Recognition
  - Winner of four domestic and international competitions in the field.
  - Published 6 papers in top-tier conferences and journals.
  - National Scholarship.
    
- *2014.09 - 2018.06*, Bachelor of Engineering, South China University of Technology.
  Information Engineering (Elite Program)
  - Received National Endeavor Scholarship for two years.
  - Recommended for postgraduate admission without an entrance exam.


# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
